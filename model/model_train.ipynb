{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT for MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"AN IMAGE IS WORTH 16X16 WORDS:  TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\": <br>\n",
    "https://arxiv.org/pdf/2010.11929 \n",
    "\n",
    "This paper was published after the transformer architecture had become the standard within NLP. This paper showed that not only could transformers be applied to computer vision, but it beats standard CNNs in complicated image classification tasks. Th paper introduces the Visual Transformer (ViT). \n",
    "\n",
    "Note that: \n",
    "- Initial attempts tried to use CNNs with attention mechanism has been tried, but where not scalable. \n",
    "- Transformers can be trained on 100B parameters! \n",
    "- Inductive bias from the transformer is handled by providing large dataset \n",
    "- ViTs had great results, but they where pre-trained on large datasets (14 to 300 million images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works well by making the images into patches and then turn them into embeddings to input to the transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
